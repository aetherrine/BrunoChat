{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import weaviate\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_retrieval(client, collection_name, embedding):\n",
    "    response = client.query.aggregate(collection_name).with_near_vector({\n",
    "        'vector': embedding,\n",
    "        'certainty': 0.7\n",
    "    }).with_limit(5).with_meta().do()\n",
    "    \n",
    "    retrieved_texts = [result['path']['text_content'] for result in response['data']['Aggregate'][collection_name]]\n",
    "\n",
    "    return retrieved_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(question, openai_client, weaviate_client, collection_name):\n",
    "    # generate question embedding\n",
    "    embedding_response = openai_client.embeddings.create(\n",
    "        input = [question.replace(\"\\n\", \" \")],\n",
    "        model = 'text-embedding-3-small'\n",
    "    )\n",
    "    print(embedding_response)\n",
    "    question_embedding = embedding_response.data[0].embedding\n",
    "\n",
    "    # retrieved_texts = context_retrieval(weaviate_client, collection_name, question_embedding)\n",
    "    retrieved_texts = \"\"\n",
    "    combined_context = \" \".join(retrieved_texts)\n",
    "    \n",
    "    # generate answer with context\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant to answer any question related to Brown University's Computer Science department.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    print(response)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "weaviate_api_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "weaviate_endpoint = os.getenv(\"WEAVIATE_WCS_URL\")\n",
    "\n",
    "# connect to a WCS instance & openai\n",
    "# weaviate_client = weaviate.connect_to_wcs(\n",
    "#     cluster_url = weaviate_endpoint,\n",
    "#     auth_credentials = weaviate.auth.AuthApiKey(weaviate_api_key),\n",
    "# )\n",
    "weaviate_client = None\n",
    "openai_client = OpenAI(api_key = openai_api_key)\n",
    "\n",
    "answer = rag(\n",
    "    question = \"What are the general research areas in Brown CS?\",\n",
    "    openai_client = openai_client,\n",
    "    weaviate_client = weaviate_client,\n",
    "    collection_name = \"CSWebsiteContent\"\n",
    ")\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brunochat-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
